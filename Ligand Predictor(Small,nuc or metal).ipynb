{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "import scikitplot as skplt\n",
    "dataset = np.load(r'C:\\Users\\Justin\\Desktop\\Unizeug\\Abgeschlossen\\PBL\\uniprot_binary_binding_2.5.npz', mmap_mode='r')\n",
    "labels = np.genfromtxt(fname = r'C:\\Users\\Justin\\Desktop\\Unizeug\\Abgeschlossen\\PBL\\binary_binding_2.5(1).txt',dtype='str')\n",
    "\n",
    "\n",
    "aminoacids = []      \n",
    "\n",
    "for protein in dataset:\n",
    "    amino = dataset[str(protein)]\n",
    "    aminoacids.append([protein, amino])\n",
    "\n",
    "aminoacids.sort()           #alphabetisch sortieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLabels = [] \n",
    "\n",
    "for protein, label in labels:                     #labels zahl zuweisen und multilabels rauskÃ¼rzen\n",
    "    if (label == 'small'):\n",
    "        newLabels.append([protein, 0])\n",
    "    elif (label == 'metal'):\n",
    "        newLabels.append([protein, 1])\n",
    "    elif (label == 'nuc'):\n",
    "        newLabels.append([protein, 2])          #small = 514,metal = 317, nuc = 86   #+428 nuc & + 197 metal = +625\n",
    "\n",
    "filteredAmino = []                     #Schnittmenge\n",
    "filteredLabels = []                    #filteredLabels = newLabels\n",
    "\n",
    "for amino in aminoacids:\n",
    "    for label in newLabels:\n",
    "        if (amino[0] == label[0]):\n",
    "            filteredAmino.append(amino[1])\n",
    "            filteredLabels.append(label[1])            #proteinId's raus\n",
    "            break\n",
    "\n",
    " \n",
    "\n",
    "                                                     #b = [[seqvec1][seqvec2]] 1119 x 1024 und l = 1119 [1,2,...] len(l) = 1119\n",
    "                                                     #b.shape = (m,n)and  l.shape should be (m)\n",
    "print(filteredAmino)\n",
    "print(filteredLabels)\n",
    "a = (np.array(filteredAmino))\n",
    "b = (np.array(filteredLabels))\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(sorted(Counter(b).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train, a_test, b_train, b_test = train_test_split(a, b, random_state = 0, test_size = 0.1)\n",
    "print(a_train)\n",
    "print(b_train)\n",
    "print(b_test)\n",
    "print(a_test)                      #test absplitten -> training set nehmen zum weiterarbeiten und zum undersampling\n",
    "print(\"Dataset sizes:\\nWhole set: {}\\nTraining Set: {}\\nTest Set: {}\".\n",
    "      format(len(b), len(b_train), len(b_test)))\n",
    "print(sorted(Counter(b_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DummyClassifier(strategy='stratified', random_state=0)        #stratified/most_frequent/uniform\n",
    "clf.fit(a_test, b_test)\n",
    "\n",
    "clf.score(a_test, b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5)\n",
    "classifier = MLPClassifier(early_stopping = True)\n",
    "\n",
    "print(format(sum(b_train==1)))\n",
    "print(format(sum(b_train==0)))\n",
    "print(format(sum(b_train==2)))\n",
    "\n",
    "sm = SMOTE(random_state = 0)\n",
    "a_train_res, b_train_res = sm.fit_sample(a_train, b_train.ravel())\n",
    "print(format(a_train_res.shape))\n",
    "print(format(b_train_res.shape))\n",
    "print(format(sum(b_train_res==1)))\n",
    "print(format(sum(b_train_res==0)))\n",
    "print(format(sum(b_train_res==2)))\n",
    "\n",
    "params ={ 'hidden_layer_sizes': [(30,)]} #testing different parameters #max_iter maybe?\n",
    "\n",
    "grid = GridSearchCV(estimator = classifier, cv = cv, param_grid = params,  \n",
    "                    return_train_score=True)\n",
    "grid.fit(a_train_res, b_train_res)\n",
    "#grid.fit(a_test,b_test)\n",
    "\n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "print(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = grid.best_estimator_\n",
    "b_pred = best_classifier.predict(a_test)\n",
    "pred_score = best_classifier.score(a_test, b_test)\n",
    "\n",
    "# Calculate confusion matrix (showing tp, fp, tn, fn)   \n",
    "cm = confusion_matrix(b_test, b_pred)\n",
    "cmn = (cm.T / cm.astype(np.float).sum(axis=1)).T\n",
    "print(cmn)\n",
    "print('Acc: {}'.format(round(pred_score, 3)))#TP + TN / n\n",
    "#precision_score(b_train_res, b_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(b_test, b_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set prediction\n",
    "print(classification_report(b_train_res, b_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(b_test,b_pred)) #test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random prediction on same set as mine\n",
    "\n",
    "bb_pred = clf.predict(a_train_res)\n",
    "pred_score = best_classifier.score(a_train_res, b_train_res)\n",
    "print(classification_report(b_train_res, bb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['small', 'metal', 'nuc']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cmn, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "skplt.metrics.plot_confusion_matrix(b_test, b_pred, normalize=True)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
